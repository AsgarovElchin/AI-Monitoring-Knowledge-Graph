# Project Description
In healthcare, the deployment of AI systems faces challenges such as model drift, bias, lack of transparency, and accountability issues. These challenges can lead to incorrect predictions, reduced trust, and regulatory non-compliance. This project provides a **Neo4j-based Provenance Knowledge Graph** designed to monitor, evaluate, and improve AI systems used in critical healthcare environments.
The primary purpose of this project is to:
1. Track Provenance: Maintain traceability for AI models, their datasets, and predictions.
2. Detect Drift and Bias: Continuously monitor model behavior for drift and bias metrics to ensure stability and fairness.
3. Mitigate Risks: Identify risks in predictions and feature changes to minimize impact.
4. Integrate Feedback: Incorporate human feedback into the AI lifecycle for iterative improvement.
# Graph Nodes and Relationships
The knowledge graph contains 96 nodes and 95 relationships, providing a comprehensive representation of the AI system. Below is a detailed breakdown of the nodes, their attributes, and their interconnections:
# Node Labels
1. Model:
   - Description: Represents AI models, including their training and performance metadata.
   - Attributes:
     - `model_id`: Unique identifier for the model.
     - `accuracy`: The model's performance accuracy.
     - `training_params`: Training parameters, such as `max_iter` or `test_size`.
     - `training_date`: The date the model was trained.
   - Purpose: Central to the graph, linking predictions, datasets, and metrics to ensure traceability.
2. Dataset:
   - Description: Represents the dataset used for training or evaluating the model.
   - Attributes:
     - `name`: Name of the dataset (e.g., "Heart Disease Dataset").
     - `version`: Dataset version for tracking updates.
   - Purpose: Ensures transparency and reproducibility by linking data provenance to the AI lifecycle.

3. Prediction:
   - Description: Represents individual predictions generated by the model.
   - Attributes:
     - `prediction_id`: Unique identifier for the prediction.
     - `input_data`: Features used for prediction (e.g., age, blood pressure).
     - `predicted_value`: The outcome predicted by the model.
     - `actual_value`: The actual ground truth for the prediction.
   - Purpose: Tracks the AI's outputs and links them to feedback and risks for evaluation.

4. Feedback:
   - Description: Captures human feedback on predictions.
   - Attributes:
     - `notes`: Comments on the prediction's correctness.
     - `timestamp`: When feedback was provided.
     - `correct`: Boolean indicating whether the prediction was accurate.
   - Purpose: Facilitates continuous improvement by incorporating human expertise.

5. DriftDetection:
   - Description: Tracks instances of detected model drift.
   - Attributes:
     - `detection_date`: The date drift was detected.
     - `drift_detected`: Boolean flag indicating whether drift occurred.
     - `drift_id`: Unique identifier for the drift event.
   - Purpose: Monitors model performance over time to detect deviations.

6. DriftMetric:
   - Description: Represents specific metrics used to quantify model drift.
   - Attributes:
     - `feature`: The feature or variable being monitored.
     - `ks_statistic`: Kolmogorov-Smirnov statistic to measure drift.
     - `p_value`: Significance level for drift detection.
     - `psi`: Population Stability Index for the feature.
   - Purpose: Provides a measurable way to monitor and act on drift.

7. Risk:
   - Description: Highlights risks associated with predictions or feature drift.
   - Attributes:
     - `risk_id`: Unique identifier for the risk instance.
     - `severity`: Severity level of the risk (e.g., Low, Medium, High).
     - `description`: A detailed explanation of the risk.
   - Purpose: Ensures high-stakes decisions are flagged and mitigated appropriately.

8. BiasMetric:
   - Description: Tracks metrics for bias evaluation, such as demographic parity.
   - Attributes:
     - `bias_id`: Unique identifier for the bias metric.
     - `male_rate`: Metric value for male demographic.
     - `female_rate`: Metric value for female demographic.
     - `value`: Overall bias measurement.
     - `metric`: Name of the metric used (e.g., "Demographic Parity").
   - Purpose: Ensures fairness and equity in AI decision-making.

9. FairnessMetric:
   - Description: Tracks fairness metrics, such as equalized odds.
   - Attributes:
     - `fpr_diff`: False Positive Rate difference across groups.
     - `tpr_diff`: True Positive Rate difference across groups.
     - `metric`: The name of the fairness metric.
     - `fairness_id`: Unique identifier for the fairness metric.
   - Purpose: Helps assess compliance with ethical standards.

# Relationship Types
1. GENERATED:
    - Links `Model` to `Prediction` .
    - Purpose: Represents outputs generated by the model.
    
2. TRAINED_ON:
   - Links `Model` to `Dataset`.
   - Purpose: Tracks the data used for training to ensure reproducibility.

3. HAS_DRIFT_DETECTION:
   - Links `Model` to `DriftDetection`.
   - Purpose: Monitors drift instances detected for the model.

4. HAS_BIAS_METRIC:
   - Links `Model` to `BiasMetric`.
   - Purpose: Tracks fairness metrics associated with the model.

5. HAS_FAIRNESS_METRIC:
   - Links `Model` to `FairnessMetric`.
   - Purpose: Monitors fairness metrics like equalized odds.

6. HAS_FEEDBACK:
   - Links `Prediction` to `Feedback`.
   - Purpose: Tracks human feedback for improving predictions.

7. HAS_DRIFT_METRIC:
   - Links `DriftDetection` to `DriftMetric`.
   - Purpose: Quantifies drift metrics for specific features.

8. POSES_RISK:
   - Links `Prediction` to `Risk`.
   - Purpose: Flags high-risk predictions for further evaluation.
# Graph Visualization

This visualization demonstrates how models, datasets, predictions, feedback, drift, and metrics are interconnected within the AI system.

![Knowledge_Graph](https://raw.githubusercontent.com/AsgarovElchin/AI-Monitoring-Knowledge-Graph/537d902346480be831aecc539f1f8ac462f842c8/graph.svg)

his is a node labels legend for the knowledge graph. It visually categorizes different types of nodes, such as Models (blue), Datasets (red), Predictions (green), and others, using distinct colors to represent each entity type in the graph.

![Node_Labels](https://github.com/AsgarovElchin/AI-Monitoring-Knowledge-Graph/blob/4f297f05ab1f6c99f931e27c8161ef29575f7f94/node_labels.png)
